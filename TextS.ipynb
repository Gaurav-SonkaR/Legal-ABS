{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24ce83cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==2.1.0\n",
      "accelerate==1.2.0\n",
      "asttokens==3.0.0\n",
      "astunparse==1.6.3\n",
      "certifi==2024.8.30\n",
      "charset-normalizer==3.4.0\n",
      "colorama==0.4.6\n",
      "comm==0.2.2\n",
      "contourpy==1.3.1\n",
      "cycler==0.12.1\n",
      "debugpy==1.8.9\n",
      "decorator==5.1.1\n",
      "executing==2.1.0\n",
      "filelock==3.16.1\n",
      "flatbuffers==24.3.25\n",
      "fonttools==4.55.3\n",
      "fsspec==2024.10.0\n",
      "gast==0.6.0\n",
      "google-pasta==0.2.0\n",
      "grpcio==1.68.1\n",
      "h5py==3.12.1\n",
      "huggingface-hub==0.26.5\n",
      "idna==3.10\n",
      "ipykernel==6.29.5\n",
      "ipython==8.30.0\n",
      "jedi==0.19.2\n",
      "Jinja2==3.1.4\n",
      "joblib==1.4.2\n",
      "jupyter_client==8.6.3\n",
      "jupyter_core==5.7.2\n",
      "keras==3.7.0\n",
      "kiwisolver==1.4.7\n",
      "libclang==18.1.1\n",
      "Markdown==3.7\n",
      "markdown-it-py==3.0.0\n",
      "MarkupSafe==3.0.2\n",
      "matplotlib==3.9.3\n",
      "matplotlib-inline==0.1.7\n",
      "mdurl==0.1.2\n",
      "ml-dtypes==0.4.1\n",
      "mpmath==1.3.0\n",
      "namex==0.0.8\n",
      "nest-asyncio==1.6.0\n",
      "networkx==3.4.2\n",
      "numpy==2.0.2\n",
      "opt_einsum==3.4.0\n",
      "optree==0.13.1\n",
      "packaging==24.2\n",
      "pandas==2.2.3\n",
      "parso==0.8.4\n",
      "pillow==11.0.0\n",
      "platformdirs==4.3.6\n",
      "prompt_toolkit==3.0.48\n",
      "protobuf==5.29.1\n",
      "psutil==6.1.0\n",
      "pure_eval==0.2.3\n",
      "Pygments==2.18.0\n",
      "pyparsing==3.2.0\n",
      "python-dateutil==2.9.0.post0\n",
      "pytz==2024.2\n",
      "pywin32==308\n",
      "PyYAML==6.0.2\n",
      "pyzmq==26.2.0\n",
      "regex==2024.11.6\n",
      "requests==2.32.3\n",
      "rich==13.9.4\n",
      "safetensors==0.4.5\n",
      "scikit-learn==1.6.0\n",
      "scipy==1.14.1\n",
      "setuptools==75.6.0\n",
      "six==1.17.0\n",
      "stack-data==0.6.3\n",
      "sympy==1.13.1\n",
      "tensorboard==2.18.0\n",
      "tensorboard-data-server==0.7.2\n",
      "tensorflow==2.18.0\n",
      "tensorflow_intel==2.18.0\n",
      "termcolor==2.5.0\n",
      "threadpoolctl==3.5.0\n",
      "tokenizers==0.21.0\n",
      "torch==2.5.1\n",
      "tornado==6.4.2\n",
      "tqdm==4.67.1\n",
      "traitlets==5.14.3\n",
      "transformers==4.47.0\n",
      "typing_extensions==4.12.2\n",
      "tzdata==2024.2\n",
      "urllib3==2.2.3\n",
      "wcwidth==0.2.13\n",
      "Werkzeug==3.1.3\n",
      "wheel==0.45.1\n",
      "wrapt==1.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a341eaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "dataset = pd.read_csv('modified_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f057549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judgment</th>\n",
       "      <th>summary</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Appeal No. LXVI of 1949. Appeal from the High ...</td>\n",
       "      <td>The charge created in respect of municipal pro...</td>\n",
       "      <td>appeal number lxvi of 1949. appeal from the hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Civil Appeal No.94 of 1949. 107 834 Appeal fro...</td>\n",
       "      <td>An agreement for a lease, which a lease is by ...</td>\n",
       "      <td>civil appeal no.94 of 1949. 107 834 appeal fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iminal Appeal No. 40 of 1951, 127 Appeal from ...</td>\n",
       "      <td>The question whether a Magistrate is \"personal...</td>\n",
       "      <td>iminal appeal number 40 of 1951, 127 appeal fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Appeal No. 388 of 1960. Appeal by special leav...</td>\n",
       "      <td>The appellant was a member of a joint Hindu fa...</td>\n",
       "      <td>appeal number 388 of 1960. appeal by special l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Appeal No. 198 of 1954. Appeal from the judgme...</td>\n",
       "      <td>The appellant was the Ruler of the State of Ba...</td>\n",
       "      <td>appeal number 198 of 1954. appeal from the jud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7123</th>\n",
       "      <td>Appeal No. 1367 of 1980. From the Judgment and...</td>\n",
       "      <td>Proceedings were commenced under Chapter III B...</td>\n",
       "      <td>appeal number 1367 of 1980. from the judgment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7124</th>\n",
       "      <td>Appeal No. 1695 of 1993. From the Judgment and...</td>\n",
       "      <td>The plaintiff, predecessor in interest of the ...</td>\n",
       "      <td>appeal number 1695 of 1993. from the judgment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7125</th>\n",
       "      <td>iminal Appeal No. 46 of 1957. Appeal by specia...</td>\n",
       "      <td>Conciliation proceedings were started in Janua...</td>\n",
       "      <td>iminal appeal number 46 of 1957. appeal by spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7126</th>\n",
       "      <td>N: Criminal Appeal No. 8 of 1951. Appeal from ...</td>\n",
       "      <td>Sub section (1) of sec.\\n19 of the Bombay Rent...</td>\n",
       "      <td>n: criminal appeal number 8 of 1951. appeal fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7127</th>\n",
       "      <td>: Civil Appeals Nos 188 to 190 of 1958. Appeal...</td>\n",
       "      <td>The principal question for determination in th...</td>\n",
       "      <td>: civil appeals nos 188 to 190 of 1958. appeal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7128 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               judgment  \\\n",
       "0     Appeal No. LXVI of 1949. Appeal from the High ...   \n",
       "1     Civil Appeal No.94 of 1949. 107 834 Appeal fro...   \n",
       "2     iminal Appeal No. 40 of 1951, 127 Appeal from ...   \n",
       "3     Appeal No. 388 of 1960. Appeal by special leav...   \n",
       "4     Appeal No. 198 of 1954. Appeal from the judgme...   \n",
       "...                                                 ...   \n",
       "7123  Appeal No. 1367 of 1980. From the Judgment and...   \n",
       "7124  Appeal No. 1695 of 1993. From the Judgment and...   \n",
       "7125  iminal Appeal No. 46 of 1957. Appeal by specia...   \n",
       "7126  N: Criminal Appeal No. 8 of 1951. Appeal from ...   \n",
       "7127  : Civil Appeals Nos 188 to 190 of 1958. Appeal...   \n",
       "\n",
       "                                                summary  \\\n",
       "0     The charge created in respect of municipal pro...   \n",
       "1     An agreement for a lease, which a lease is by ...   \n",
       "2     The question whether a Magistrate is \"personal...   \n",
       "3     The appellant was a member of a joint Hindu fa...   \n",
       "4     The appellant was the Ruler of the State of Ba...   \n",
       "...                                                 ...   \n",
       "7123  Proceedings were commenced under Chapter III B...   \n",
       "7124  The plaintiff, predecessor in interest of the ...   \n",
       "7125  Conciliation proceedings were started in Janua...   \n",
       "7126  Sub section (1) of sec.\\n19 of the Bombay Rent...   \n",
       "7127  The principal question for determination in th...   \n",
       "\n",
       "                                      preprocessed_text  \n",
       "0     appeal number lxvi of 1949. appeal from the hi...  \n",
       "1     civil appeal no.94 of 1949. 107 834 appeal fro...  \n",
       "2     iminal appeal number 40 of 1951, 127 appeal fr...  \n",
       "3     appeal number 388 of 1960. appeal by special l...  \n",
       "4     appeal number 198 of 1954. appeal from the jud...  \n",
       "...                                                 ...  \n",
       "7123  appeal number 1367 of 1980. from the judgment ...  \n",
       "7124  appeal number 1695 of 1993. from the judgment ...  \n",
       "7125  iminal appeal number 46 of 1957. appeal by spe...  \n",
       "7126  n: criminal appeal number 8 of 1951. appeal fr...  \n",
       "7127  : civil appeals nos 188 to 190 of 1958. appeal...  \n",
       "\n",
       "[7128 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d929a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(dataset['preprocessed_text'])\n",
    "y = list(dataset['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdf92951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7128\n"
     ]
    }
   ],
   "source": [
    "\n",
    "len_list = []\n",
    "for x in X:\n",
    "    len_list.append(len(x))\n",
    "print(len(len_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03224f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 0., ..., 0., 0., 1.]),\n",
       " array([7.13000000e+02, 7.94066000e+02, 8.75132000e+02, ...,\n",
       "        8.11210868e+05, 8.11291934e+05, 8.11373000e+05]),\n",
       " <BarContainer object of 10000 artists>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.hist(len_list, bins=10000, color='skyblue', edgecolor='black', alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46dc796d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1328\n"
     ]
    }
   ],
   "source": [
    "X_temp = []\n",
    "y_temp = []\n",
    "for i in range(len(X)):\n",
    "    if len(X[i]) <=10000:\n",
    "        X_temp.append(X[i])\n",
    "        y_temp.append(y[i])\n",
    "\n",
    "print(len(X_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a085d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_temp\n",
    "y = y_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e6c601c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test , y_train , y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9066a2c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.bart.modeling_bart because of the following error (look up to see its traceback):\nNo module named 'distutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32me:\\GAURAV legal dataset\\legalenv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1793\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1792\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1793\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mE:\\Python_Install_Files\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32me:\\GAURAV legal dataset\\legalenv\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:44\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_outputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     36\u001b[0m     BaseModelOutput,\n\u001b[0;32m     37\u001b[0m     BaseModelOutputWithPastAndCrossAttentions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m     Seq2SeqSequenceClassifierOutput,\n\u001b[0;32m     43\u001b[0m )\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     46\u001b[0m     add_code_sample_docstrings,\n\u001b[0;32m     47\u001b[0m     add_end_docstrings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     53\u001b[0m     replace_return_docstrings,\n\u001b[0;32m     54\u001b[0m )\n",
      "File \u001b[1;32me:\\GAURAV legal dataset\\legalenv\\Lib\\site-packages\\transformers\\modeling_utils.py:48\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftAdapterMixin, deepspeed_config, is_deepspeed_zero3_enabled\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LOSS_MAPPING\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     Conv1D,\n\u001b[0;32m     51\u001b[0m     apply_chunking_to_forward,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m     translate_to_torch_parallel_style,\n\u001b[0;32m     59\u001b[0m )\n",
      "File \u001b[1;32me:\\GAURAV legal dataset\\legalenv\\Lib\\site-packages\\transformers\\loss\\loss_utils.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BCEWithLogitsLoss, MSELoss\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_deformable_detr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_for_object_detection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ForObjectDetectionLoss, ForSegmentationLoss\n",
      "File \u001b[1;32me:\\GAURAV legal dataset\\legalenv\\Lib\\site-packages\\transformers\\loss\\loss_deformable_detr.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_transforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m center_to_corners_format\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_scipy_available\n",
      "File \u001b[1;32me:\\GAURAV legal dataset\\legalenv\\Lib\\site-packages\\transformers\\image_transforms.py:50\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_tf_available():\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_flax_available():\n",
      "File \u001b[1;32me:\\GAURAV legal dataset\\legalenv\\Lib\\site-packages\\tensorflow\\__init__.py:30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-bad-import-order,protected-access,g-import-not-at-top\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_distutils\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'distutils'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BartForConditionalGeneration, BartTokenizer\n\u001b[0;32m      3\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/bart-large-cnn\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load model and tokenizer with no progress bar\u001b[39;00m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32me:\\GAURAV legal dataset\\legalenv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1782\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1781\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m-> 1782\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n\u001b[0;32m   1784\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n",
      "File \u001b[1;32me:\\GAURAV legal dataset\\legalenv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1781\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1779\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1781\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1782\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "File \u001b[1;32me:\\GAURAV legal dataset\\legalenv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1795\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1793\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1795\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1796\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1797\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1798\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.models.bart.modeling_bart because of the following error (look up to see its traceback):\nNo module named 'distutils'"
     ]
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "\n",
    "# Load model and tokenizer with no progress bar\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name, use_progress_bar=False)\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3783cfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement distutils (from versions: none)\n",
      "ERROR: No matching distribution found for distutils\n"
     ]
    }
   ],
   "source": [
    "!pip install distutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c61a2dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoding = tokenizer(X_train,max_length=1024,truncation=True, padding=\"max_length\" )\n",
    "test_encoding = tokenizer(X_test ,max_length= 1024,truncation=True, padding=\"max_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6a6bab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_encoding['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50b85ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_encoding['attention_mask'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0618ddd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 11:29:45.116025: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-06 11:29:45.177212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14152 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encoding),\n",
    "    y_train\n",
    "))\n",
    "\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_encoding),\n",
    "    y_test\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b09c0721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('4.46.3', '1.1.1')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import accelerate\n",
    "import transformers\n",
    "\n",
    "transformers.__version__, accelerate.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2783e289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=({'input_ids': TensorSpec(shape=(1024,), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(1024,), dtype=tf.int32, name=None)}, TensorSpec(shape=(), dtype=tf.string, name=None))>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8497848c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from transformers import TrainingArguments\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir = \"./our-model\",\n",
    "#     learning_rate=2e-5,\n",
    "#     per_device_train_batch_size= 64,\n",
    "#     per_device_eval_batch_size = 16,\n",
    "#     num_train_epochs = 2,\n",
    "#     weight_decay = 0.01,\n",
    "#     evaluation_strategy = \"epoch\",\n",
    "#     save_strategy = \"epoch\",\n",
    "#     load_best_model_at_end = True,\n",
    "#     push_to_hub = False\n",
    "# )\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=2,  # Adjust as needed\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size= 4,\n",
    "    warmup_steps=500,\n",
    "    weight_decay = 0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=1000,\n",
    "\n",
    "    # save_steps=10_000,\n",
    "    # save_total_limit=2,\n",
    "    # evaluation_strategy=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56dbe7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8373065",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 33.25 MiB is free. Including non-PyTorch memory, this process has 15.46 GiB memory in use. Of the allocated memory 1.48 GiB is allocated by PyTorch, and 10.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[0;32m----> 2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/deprecation.py:165\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS):\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:574\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m# Bnb Quantized models doesn't support `.to` operation.\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplace_model_on_device\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_method\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m QuantizationMethod\u001b[38;5;241m.\u001b[39mBITS_AND_BYTES\n\u001b[1;32m    573\u001b[0m ):\n\u001b[0;32m--> 574\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_move_model_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_model_parallel:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:846\u001b[0m, in \u001b[0;36mTrainer._move_model_to_device\u001b[0;34m(self, model, device)\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_move_model_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, device):\n\u001b[0;32m--> 846\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    847\u001b[0m     \u001b[38;5;66;03m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[39;00m\n\u001b[1;32m    848\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mparallel_mode \u001b[38;5;241m==\u001b[39m ParallelMode\u001b[38;5;241m.\u001b[39mTPU \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtie_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_utils.py:3157\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   3153\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3154\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3155\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3156\u001b[0m         )\n\u001b[0;32m-> 3157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 900 (3 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1321\u001b[0m             device,\n\u001b[1;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1323\u001b[0m             non_blocking,\n\u001b[1;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 33.25 MiB is free. Including non-PyTorch memory, this process has 15.46 GiB memory in use. Of the allocated memory 1.48 GiB is allocated by PyTorch, and 10.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = test_dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "33cdaf55",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate(test_dataset)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.evaluate(test_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a2f00f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc1a17c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legalenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
